{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOYVivZO9mrs"
      },
      "outputs": [],
      "source": [
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"/content/AD.zip\", 'r') as zObject:\n",
        "\n",
        "    # Extracting all the members of the zip\n",
        "    # into a specific location.\n",
        "    zObject.extractall(\n",
        "        path=\"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"/content/TD.zip\", 'r') as zObject:\n",
        "\n",
        "    # Extracting all the members of the zip\n",
        "    # into a specific location.\n",
        "    zObject.extractall(\n",
        "        path=\"/content\")"
      ],
      "metadata": {
        "id": "epKzw1oQ3jQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "repeat for combination (C3, Cz) and (C3,C4)"
      ],
      "metadata": {
        "id": "asXZEa7pSrjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pywavelets\n",
        "import pandas as pd\n",
        "ns =11\n",
        "ori_data = dict()\n",
        "mod_data = dict()\n",
        "ori_data1 = dict()\n",
        "mod_data1 = dict()\n",
        "# function to count subject\n",
        "def subjectCounter(i):\n",
        "    return 'subject0{}'.format(i)\n",
        "for i in range(1, ns):\n",
        "    data_path = '/content/AD/AD/AV{:02d}.xlsx'.format(i)\n",
        "    subj = subjectCounter(i)\n",
        "    ori_data[subj] =  pd.read_excel(data_path, usecols=['C4','Cz'])\n",
        "    mod_data[subj] = {}\n",
        "    mod_data[subj]['raw_EEG'] = ori_data[subj]\n",
        "for i in range(1, ns):\n",
        "    data_path = '/content/TD/TD{:02d}.xlsx'.format(i)\n",
        "    subj = subjectCounter(i)\n",
        "    ori_data1[subj] =  pd.read_excel(data_path, usecols=['C4','Cz'])\n",
        "    mod_data1[subj] = {}\n",
        "    mod_data1[subj]['raw_EEG'] = ori_data1[subj]"
      ],
      "metadata": {
        "id": "xWvcunpqSVft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztl9RQqPn1FG"
      },
      "outputs": [],
      "source": [
        "from scipy import signal\n",
        "for i in range(1, ns):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data[subj] = {}\n",
        "for i in range(1, ns):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data1[subj] = {}\n",
        "for i in range(1, ns):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data[subj]['raw_EEG'] = ori_data[subj]\n",
        "for i in range(1, ns):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data1[subj]['raw_EEG'] = ori_data1[subj]\n",
        "from scipy.signal import butter, lfilter\n",
        "from scipy.signal import freqz\n",
        "from scipy.signal import butter, filtfilt\n",
        "def butter_bandpass_filter(signal, lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut/nyq\n",
        "    high = highcut/nyq\n",
        "    b,a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, signal)\n",
        "    return y\n",
        "for i in range(1, ns):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data[subj]['raw_EEG'] = mod_data[subj]['raw_EEG'].T\n",
        "for i in range(1, ns):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data1[subj]['raw_EEG'] = mod_data1[subj]['raw_EEG'].T\n",
        "import pywt\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "def dwt_bandpass_one_subject(data, subj, lowcut, highcut, fs, interval=None):\n",
        "    data[subj]['EEG_filtered'] = {}\n",
        "    temp_raw_EEG = data[subj]['raw_EEG']\n",
        "    temp_band = 'temp_band'  # Replace 'your_desired_key' with the actual key in your dictionary\n",
        "    if interval is not None:\n",
        "        startband = np.arange(lowcut, highcut, step=interval)\n",
        "        for start in startband:\n",
        "            temp_band = \"{:02d}_{:02d}\".format(start, start+interval)\n",
        "            data[subj]['EEG_filtered']['temp_band'] = {}\n",
        "            data[subj]['EEG_filtered']['temp_band'] = dwt_bandpass_filter(temp_raw_EEG, start, start+interval, fs)\n",
        "    else:\n",
        "        temp_band = \"{:02d}_{:02d}\".format(lowcut, highcut)\n",
        "        data[subj]['EEG_filtered']['temp_band'] = {}\n",
        "        data[subj]['EEG_filtered']['temp_band'] = dwt_bandpass_filter(temp_raw_EEG, lowcut, highcut, fs)\n",
        "def dwt_bandpass_filter(data, lowcut, highcut, fs):\n",
        "    coeffs = pywt.wavedec(data, 'db4', level=3)\n",
        "    bands = [(0.5, 32)]\n",
        "    subband_filters = []\n",
        "    for low, high in bands:\n",
        "        b, a = signal.butter(5, [low/(fs/2), high/(fs/2)], btype='bandpass')\n",
        "    for i in range(1, 4):\n",
        "        for j in range(0, 3):\n",
        "            coeffs[i][j] = signal.filtfilt(b, a, coeffs[i][j])\n",
        "    filtered_data = pywt.waverec(coeffs, 'db4')\n",
        "    return filtered_data\n",
        "lowcut=8\n",
        "highcut=32\n",
        "fs = 500\n",
        "temp_band = 'temp_band'\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    dwt_bandpass_one_subject(mod_data, subj, lowcut, highcut, fs, interval = None)\n",
        "lowcut=8\n",
        "highcut=32\n",
        "fs = 500\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    dwt_bandpass_one_subject(mod_data1, subj, lowcut, highcut, fs, interval = None)\n",
        "def butter_bandpass_one_subject(data, subj, lowcut, highcut, fs, interval=None):\n",
        "    data[subj]['filtered'] = {}\n",
        "    temp_raw_EEG = data[subj]['EEG_filtered']['temp_band']\n",
        "    if interval is not None:\n",
        "        startband = np.arange(lowcut, highcut, step = interval)\n",
        "        for start in startband:\n",
        "            band = \"{:02d}_{:02d}\".format(start, start+interval)\n",
        "            data[subj]['filtered'][band] = {}\n",
        "            data[subj]['filtered'][band]['EEG_all'] = butter_bandpass_filter(temp_raw_EEG, start, start+interval, fs, order=5)\n",
        "    else:\n",
        "        band = \"{:02d}_{:02d}\".format(lowcut, highcut)\n",
        "        data[subj]['EEG_filtered'][band]['EEG_all'] = butter_bandpass_filter(temp_raw_EEG, lowcut, highcut, fs)\n",
        "lowcut=8\n",
        "highcut=32\n",
        "fs = 500\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    butter_bandpass_one_subject(mod_data, subj, lowcut, highcut, fs, interval = 4)\n",
        "lowcut=8\n",
        "highcut=32\n",
        "fs = 500\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    butter_bandpass_one_subject(mod_data1, subj, lowcut, highcut, fs, interval = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da3BFJjaV1C5"
      },
      "outputs": [],
      "source": [
        "ASD = 'ASD'\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    print('Processing ', subj)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        temp_EEG_all = mod_data[subj]['filtered'][band]['EEG_all']\n",
        "        temp_ASD = []\n",
        "        for j in range(0,61):\n",
        "            subset_size = 1000\n",
        "            temp_ASD.append(temp_EEG_all[:,j * subset_size:(j+1) * subset_size])\n",
        "        mod_data[subj]['filtered'][band]['ASD'] = np.array(temp_ASD)\n",
        "TD = 'TD'\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    print('Processing ', subj)\n",
        "    for band in mod_data1[subj]['filtered'].keys():\n",
        "        temp_EEG_all = mod_data1[subj]['filtered'][band]['EEG_all']\n",
        "        temp_TD = []\n",
        "        for j in range(0,61):\n",
        "            subset_size = 1000\n",
        "            temp_TD.append(temp_EEG_all[:,j * subset_size:(j+1) * subset_size])\n",
        "        mod_data1[subj]['filtered'][band]['TD'] = np.array(temp_TD)\n",
        "def split_EEG_one_class(EEG_one_class, percent_train=0.8):\n",
        "    n = EEG_one_class.shape[0]\n",
        "    n_tr = round(n*percent_train)\n",
        "    n_te = n - n_tr\n",
        "    EEG_train = EEG_one_class[:n_tr]\n",
        "    EEG_test = EEG_one_class[n_tr:n_tr+n_te]\n",
        "    return EEG_train, EEG_test\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        temp_EEG_ASD = mod_data[subj]['filtered'][band]['EEG_ASD']\n",
        "        temp_filt = mod_data[subj]['filtered'][band]\n",
        "        temp_filt['EEG_ASD_train'], temp_filt['EEG_ASD_test'] = split_EEG_one_class(temp_EEG_ASD, 0.8)\n",
        "        print(temp_filt['EEG_ASD_test'])\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data1[subj]['filtered'].keys():\n",
        "        temp_EEG_TD = mod_data1[subj]['filtered'][band]['EEG_TD']\n",
        "        temp_filt = mod_data1[subj]['filtered'][band]\n",
        "        temp_filt['EEG_TD_train'], temp_filt['EEG_TD_test'] = split_EEG_one_class(temp_EEG_TD, 0.8)\n",
        "for i in range(1, ns):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data[subj]['CSP'] = {}\n",
        "for i in range(1, ns):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data1[subj]['CSP'] = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.covariance import GraphicalLasso, GraphicalLassoCV\n",
        "def compute_cov(EEG_data):\n",
        "    cov = []\n",
        "    alpha = 0.1\n",
        "    for i in range(EEG_data.shape[0]):\n",
        "        cov.append(EEG_data[i]@EEG_data[i].T/np.trace(EEG_data[i]@EEG_data[i].T))\n",
        "    cov = np.mean(np.array(cov), 0)\n",
        "    return cov\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        temp_band = mod_data[subj]['CSP'][band] = {}\n",
        "        temp_band1 = mod_data1[subj]['CSP'][band] = {}\n",
        "        temp_band['cov_ASD'] = compute_cov(mod_data[subj]['filtered'][band]['EEG_ASD_train'])\n",
        "        temp_band1['cov_TD'] = compute_cov(mod_data1[subj]['filtered'][band]['EEG_TD_train'])\n",
        "        temp_band['cov_comp'] = temp_band['cov_ASD'] + temp_band1['cov_TD']\n",
        "        print(temp_band['cov_comp'])"
      ],
      "metadata": {
        "id": "PCgGILOtt-tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZeybL4XXl8J"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        mod_data[subj]['CSP'][band]['whitening'] = {}\n",
        "from scipy.linalg import sqrtm\n",
        "from scipy.linalg import inv\n",
        "def decompose_cov(avg_cov):\n",
        "    λ, V = np.linalg.eig(avg_cov)\n",
        "    λ_dsc = np.sort(λ)[::-1]\n",
        "    idx_dsc = np.argsort(λ)[::-1]\n",
        "    V_dsc = V[:, idx_dsc]\n",
        "    λ_dsc = np.diag(λ_dsc)\n",
        "    return λ_dsc, V_dsc\n",
        "def white_matrix(λ_dsc, V_dsc):\n",
        "    λ_dsc_sqr = sqrtm(inv(λ_dsc))\n",
        "    P = (λ_dsc_sqr)@(V_dsc.T)\n",
        "    return P\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        temp_whitening = mod_data[subj]['CSP'][band]['whitening']\n",
        "        temp_cov = mod_data[subj]['CSP'][band]['cov_comp']\n",
        "        temp_whitening['eigval'], temp_whitening['eigvec'] = decompose_cov(temp_cov)\n",
        "        temp_whitening['P'] = white_matrix(temp_whitening['eigval'], temp_whitening['eigvec'])\n",
        "        print(temp_whitening['eigvec'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_RQ2AljX7oE"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        mod_data[subj]['CSP'][band]['S_ASD'] = {}\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data1[subj]['filtered'].keys():\n",
        "        mod_data1[subj]['CSP'][band]['S_TD'] = {}\n",
        "def compute_S(avg_Cov, white):\n",
        "    S = white@avg_Cov@white.T\n",
        "    return S\n",
        "def decompose_S(S_one_class, order='descending'):\n",
        "    λ, B = np.linalg.eig(S_one_class)\n",
        "    if order == 'ascending':\n",
        "        idx = λ.argsort()\n",
        "    elif order == 'descending':\n",
        "        idx = λ.argsort()[::-1]\n",
        "    else:\n",
        "        print('Wrong order input')\n",
        "    λ = λ[idx]\n",
        "    B = B[:, idx]\n",
        "    return B, λ\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        temp_P = mod_data[subj]['CSP'][band]['whitening']['P']\n",
        "        Cl = mod_data[subj]['CSP'][band]['cov_ASD']\n",
        "        temp_Sl = mod_data[subj]['CSP'][band]['S_ASD']\n",
        "        Sl = compute_S(Cl, temp_P)\n",
        "        temp_Sl['eigvec'], temp_Sl['eigval'] = decompose_S(Sl, 'descending')\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data1[subj]['filtered'].keys():\n",
        "        temp_P = mod_data[subj]['CSP'][band]['whitening']['P']\n",
        "        Cr = mod_data1[subj]['CSP'][band]['cov_TD']\n",
        "        temp_Sr = mod_data1[subj]['CSP'][band]['S_TD']\n",
        "        Sr = compute_S(Cr, temp_P)\n",
        "        temp_Sr['eigvec'], temp_Sr['eigval'] = decompose_S(Sr, 'ascending')\n",
        "        print(temp_Sr['eigval'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kx_jQB3Zglq"
      },
      "outputs": [],
      "source": [
        "def spatial_filter(B, P):\n",
        "    return (B.T@P)\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        temp_eigvec = mod_data[subj]['CSP'][band]['S_ASD']['eigvec']\n",
        "        temp_P = mod_data[subj]['CSP'][band]['whitening']['P']\n",
        "        mod_data[subj]['CSP'][band]['W'] = spatial_filter(temp_eigvec, temp_P)\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data1[subj]['filtered'].keys():\n",
        "        temp_eigvec = mod_data1[subj]['CSP'][band]['S_TD']['eigvec']\n",
        "        temp_P = mod_data[subj]['CSP'][band]['whitening']['P']\n",
        "        mod_data1[subj]['CSP'][band]['W'] = spatial_filter(temp_eigvec, temp_P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa0MK_scczMo"
      },
      "outputs": [],
      "source": [
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data[subj]['train'] = {}\n",
        "    mod_data[subj]['test'] = {}\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        mod_data[subj]['train'][band] = {}\n",
        "        mod_data[subj]['test'][band] = {}\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    mod_data1[subj]['train'] = {}\n",
        "    mod_data1[subj]['test'] = {}\n",
        "    for band in mod_data1[subj]['filtered'].keys():\n",
        "        mod_data1[subj]['train'][band] = {}\n",
        "        mod_data1[subj]['test'][band] = {}\n",
        "m = 2\n",
        "def compute_Z(W, E, m):\n",
        "    Z = []\n",
        "    W = np.delete(W, np.s_[m:-m:], 0)\n",
        "    for i in range(E.shape[0]):\n",
        "        Z.append(W @ E[i])\n",
        "    return np.array(Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat feature extraction process then include Stockwell transform and peak frequency with peak-to-peak amplitude feature"
      ],
      "metadata": {
        "id": "yMREPSvGCh8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stockwell\n",
        "import numpy as np\n",
        "from stockwell import st  # Assuming this is a valid import for the Stockwell transform\n",
        "from scipy.signal import welch\n",
        "def feat_vector(Z):\n",
        "    feat = []\n",
        "    fs = 500  # Sampling frequency (adjust as necessary)\n",
        "    fmin = 8  # Minimum frequency (Hz)\n",
        "    fmax = 32  # Maximum frequency (Hz)\n",
        "\n",
        "    for i in range(Z.shape[0]):\n",
        "        # Calculate peak-to-peak amplitude and its sum\n",
        "        peak_to_peak = np.ptp(Z[i], axis=1)  # Calculate peak-to-peak amplitude along each signal\n",
        "        peak_to_peak_sum = np.sum(peak_to_peak)  # Sum of peak-to-peak values for normalization\n",
        "\n",
        "        # Initialize list to store mean features from Stockwell transform\n",
        "        matrix_entropy = []\n",
        "        mean_features_list = []\n",
        "        peak_frequencies = []\n",
        "\n",
        "        for signal in Z[i]:\n",
        "            # Calculate frequency resolution\n",
        "            signal_length = len(signal)\n",
        "            df = fs / signal_length  # Frequency step in Hz\n",
        "            fmin_samples = int(fmin / df)  # Convert frequency to sample index\n",
        "            fmax_samples = int(fmax / df)  # Convert frequency to sample index\n",
        "\n",
        "            #Stockwell transform and extract mean features\n",
        "            stock = st.st(signal)  # Compute Stockwell Transform for the signal\n",
        "            stock = stock[fmin_samples:fmax_samples]  # Filter frequencies of interest\n",
        "            mean_features = np.mean(np.abs(stock))  # Mean of absolute values in the frequency range\n",
        "            mean_features_list.append(mean_features)\n",
        "            freqs, psd = welch(signal, fs, nperseg=min(len(signal), 256))  # Use a safe nperseg\n",
        "            #psd_norm = psd / np.sum(psd)  # Normalize the power spectral density\n",
        "            #spectral_ent = -np.sum(psd_norm * np.log2(psd_norm + 1e-12))  # Compute spectral entropy\n",
        "            #matrix_entropy.append(spectral_ent)\n",
        "            band_indices = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
        "            if np.any(band_indices):  # Ensure there is data in the range\n",
        "                peak_freq = freqs[band_indices][np.argmax(psd[band_indices])]\n",
        "                peak_frequencies.append(peak_freq)\n",
        "        # Normalize peak-to-peak and calculate log10 for each signal\n",
        "        normalized_peak_to_peak = peak_to_peak / peak_to_peak_sum if peak_to_peak_sum > 0 else np.zeros_like(peak_to_peak)\n",
        "        log10_peak_to_peak = np.log10(normalized_peak_to_peak, where=normalized_peak_to_peak > 0)  # Avoid log10(0)\n",
        "        # Append features\n",
        "        feat.append(np.concatenate((log10_peak_to_peak, [np.mean(peak_frequencies)], [np.mean(mean_features_list)])))\n",
        "    return np.array(feat)"
      ],
      "metadata": {
        "id": "W746ueKiC84_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        temp_W = mod_data[subj]['CSP'][band]['W']\n",
        "        print(len(temp_W))\n",
        "        temp_EEG_ASD = mod_data[subj]['filtered'][band]['ASD']\n",
        "        print(len(temp_EEG_ASD))\n",
        "        mod_data[subj]['train'][band]['Z_ASD'] = compute_Z(temp_W, temp_EEG_ASD, m)\n",
        "        mod_data[subj]['train'][band]['feat_ASD'] = feat_vector(mod_data[subj]['train'][band]['Z_ASD'])\n",
        "        ASD_label = np.zeros([len(mod_data[subj]['train'][band]['feat_ASD']), 1])\n",
        "    for band in mod_data1[subj]['filtered'].keys():\n",
        "        temp_W1 = mod_data1[subj]['CSP'][band]['W']\n",
        "        temp_EEG_ = mod_data1[subj]['filtered'][band]['TD']\n",
        "        mod_data1[subj]['train'][band]['Z_TD'] = compute_Z(temp_W1, temp_EEG_TD, m)\n",
        "        mod_data1[subj]['train'][band]['feat_TD'] = feat_vector(mod_data1[subj]['train'][band]['Z_TD'])\n",
        "        TD_label = np.ones([len(mod_data1[subj]['train'][band]['feat_TD']), 1])\n",
        "        ASD  = np.c_[mod_data[subj]['train'][band]['feat_ASD'], ASD_label]\n",
        "        TD  = np.c_[mod_data1[subj]['train'][band]['feat_TD'], TD_label]\n",
        "        mod_data[subj]['train'][band]['feat_train'] = np.vstack([ASD, TD])\n",
        "        np.random.shuffle(mod_data[subj]['train'][band]['feat_train'])"
      ],
      "metadata": {
        "id": "ZzX4BfmqDRd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    feat_ASD_all = []\n",
        "    feat_TD_all = []\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        feat_ASD = mod_data[subj]['train'][band]['feat_ASD']\n",
        "        feat_ASD_all.append(feat_ASD)\n",
        "        feat_TD = mod_data1[subj]['train'][band]['feat_TD']\n",
        "        feat_TD_all.append(feat_TD)\n",
        "    merge_ASD = np.zeros(feat_ASD_all[0].shape)\n",
        "    for i in feat_ASD_all:\n",
        "        merge_ASD = np.concatenate([merge_ASD, i], axis=1)\n",
        "    merge_TD = np.zeros(feat_TD_all[0].shape)\n",
        "    for i in feat_TD_all:\n",
        "        merge_TD = np.concatenate([merge_TD, i], axis=1)\n",
        "    true_ASD = np.zeros([merge_ASD.shape[0], 1])\n",
        "    true_TD = np.ones([merge_TD.shape[0], 1])\n",
        "    ASD = np.hstack([merge_ASD, true_ASD])\n",
        "    TD = np.hstack([merge_TD, true_TD])\n",
        "    train_feat = np.vstack([ASD, TD])\n",
        "    np.random.shuffle(train_feat)\n",
        "    mod_data[subj]['train']['all_band'] = train_feat\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif  # You can use f_classif for ANOVA F-statistic as an example\n",
        "def calculate_correlation_coefficient(X, y):\n",
        "    correlation_coefficients = []\n",
        "    for feature in range(X.shape[1]):\n",
        "        correlation, _ = pearsonr(X[:, feature], y)\n",
        "        correlation_coefficients.append(correlation)\n",
        "    return np.array(correlation_coefficients)\n",
        "all_subjects_data = []\n",
        "columns = ['Subject'] + [f'Feature_{i+1}' for i in range(4)] + ['Label']\n",
        "\n",
        "for i in range(1, 11):  # Loop through 10 subjects\n",
        "    subj = subjectCounter(i)  # Get subject index or identifier\n",
        "    X_train = mod_data[subj]['train']['all_band'][:, :-1]  # Features\n",
        "    y_train = mod_data[subj]['train']['all_band'][:, -1]   # Labels\n",
        "\n",
        "    # Initialize dictionary for mutual features if not already done\n",
        "    mod_data[subj]['train']['mutual'] = {}\n",
        "\n",
        "    # Calculate correlation coefficients for feature selection\n",
        "    correlation_coefficients = calculate_correlation_coefficient(X_train, y_train)\n",
        "\n",
        "    # Ensure SelectKBest is properly used\n",
        "    select = SelectKBest(score_func=lambda X, y: correlation_coefficients, k=4)\n",
        "    X_selected = select.fit_transform(X_train, y_train)\n",
        "\n",
        "    # Save selected features and labels in `mod_data`\n",
        "    mod_data[subj]['train']['mutual']['X'] = X_selected\n",
        "    mod_data[subj]['train']['mutual']['y'] = y_train\n",
        "\n",
        "    # Append data for each row to all_subjects_data\n",
        "    for j in range(X_selected.shape[0]):\n",
        "        row_data = [f'Subject_{subj}'] + X_selected[j, :].tolist() + [y_train[j]]\n",
        "        all_subjects_data.append(row_data)\n",
        "\n",
        "# Create DataFrame from collected data\n",
        "df = pd.DataFrame(all_subjects_data, columns=columns)\n",
        "\n",
        "# Save to Excel\n",
        "output_filename = 'selected_train_features_all_subjects.xlsx'\n",
        "df.to_excel(output_filename, index=False)\n",
        "\n",
        "np.random.seed(42)\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        temp_W = mod_data[subj]['CSP'][band]['W']\n",
        "        temp_EEG_ASD = mod_data[subj]['filtered'][band]['EEG_ASD_test']\n",
        "        mod_data[subj]['test'][band]['Z_ASD'] = compute_Z(temp_W, temp_EEG_ASD, m)\n",
        "        mod_data[subj]['test'][band]['feat_ASD'] = feat_vector(mod_data[subj]['test'][band]['Z_ASD'])\n",
        "        ASD_label = np.zeros([len(mod_data[subj]['test'][band]['feat_ASD']), 1])\n",
        "    for band in mod_data1[subj]['filtered'].keys():\n",
        "        temp_W1 = mod_data1[subj]['CSP'][band]['W']\n",
        "        temp_EEG_TD = mod_data1[subj]['filtered'][band]['EEG_TD_test']\n",
        "        mod_data1[subj]['test'][band]['Z_TD'] = compute_Z(temp_W1, temp_EEG_TD, m)\n",
        "        #print(np.shape(mod_data1[subj]['test'][band]['Z_TD'])[0])\n",
        "\n",
        "        mod_data1[subj]['test'][band]['feat_TD'] = feat_vector(mod_data1[subj]['test'][band]['Z_TD'])\n",
        "        #print(mod_data1[subj]['test'][band]['feat_TD'])\n",
        "        TD_label = np.ones([len(mod_data1[subj]['test'][band]['feat_TD']), 1])\n",
        "\n",
        "        ASD  = np.c_[mod_data[subj]['test'][band]['feat_ASD'], ASD_label]\n",
        "        TD  = np.c_[mod_data1[subj]['test'][band]['feat_TD'], TD_label]\n",
        "\n",
        "        mod_data[subj]['test'][band]['feat_test'] = np.vstack([ASD, TD])\n",
        "\n",
        "        np.random.shuffle(mod_data[subj]['test'][band]['feat_test'])\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "\n",
        "    feat_ASD_all = []\n",
        "    feat_TD_all = []\n",
        "\n",
        "    for band in mod_data[subj]['filtered'].keys():\n",
        "        # Access ASD each band\n",
        "        feat_ASD = mod_data[subj]['test'][band]['feat_ASD']\n",
        "\n",
        "        feat_ASD_all.append(feat_ASD)\n",
        "\n",
        "        # Access TD each band\n",
        "        feat_TD = mod_data1[subj]['test'][band]['feat_TD']\n",
        "\n",
        "        feat_TD_all.append(feat_TD)\n",
        "\n",
        "    # MERGING (Need to find more efficient method)\n",
        "    # ASD\n",
        "    merge_ASD = np.zeros(feat_ASD_all[0].shape)\n",
        "\n",
        "    for i in feat_ASD_all:\n",
        "        merge_ASD = np.concatenate([merge_ASD, i], axis=1)\n",
        "\n",
        "    # Delete initial zeros\n",
        "    merge_ASD = np.delete(merge_ASD, np.s_[:2*m], axis=1)\n",
        "\n",
        "    # TD\n",
        "    merge_TD = np.zeros(feat_TD_all[0].shape)\n",
        "\n",
        "    for i in feat_TD_all:\n",
        "        merge_TD = np.concatenate([merge_TD, i], axis=1)\n",
        "\n",
        "    # Delete initial zeros\n",
        "    merge_TD = np.delete(merge_TD, np.s_[:2*m], axis=1)\n",
        "\n",
        "    # TRUE LABEL\n",
        "    true_ASD = np.zeros([merge_ASD.shape[0], 1])\n",
        "    true_TD = np.ones([merge_TD.shape[0], 1])\n",
        "\n",
        "    # FEATURE + TRUE LABEL\n",
        "    ASD = np.hstack([merge_ASD, true_ASD])\n",
        "    TD = np.hstack([merge_TD, true_TD])\n",
        "\n",
        "    # MERGE ASD AND TD\n",
        "    test_feat = np.vstack([ASD, TD])\n",
        "\n",
        "    np.random.shuffle(test_feat)\n",
        "\n",
        "    mod_data[subj]['test']['all_band'] = test_feat\n",
        "#print(len(test_feat))\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif# You can use f_classif for ANOVA F-statistic as an example\n",
        "all_subjects_data = []\n",
        "columns = ['Subject'] + [f'Feature_{i+1}' for i in range(4)] + ['Label']\n",
        "# Define a function to calculate the Pearson correlation coefficient\n",
        "def calculate_correlation_coefficient(X, y):\n",
        "    correlation_coefficients = []\n",
        "    for feature in range(X.shape[1]):\n",
        "        correlation, _ = pearsonr(X[:, feature], y)\n",
        "        correlation_coefficients.append(correlation)\n",
        "    return np.array(correlation_coefficients)\n",
        "for i in range(1, 11):\n",
        "    subj = subjectCounter(i)\n",
        "\n",
        "    X_test = mod_data[subj]['test']['all_band'][:, :-1]\n",
        "    y_test = mod_data[subj]['test']['all_band'][:, -1]\n",
        "\n",
        "    # New dictionary to store result\n",
        "    mod_data[subj]['test']['mutual'] = {}\n",
        "\n",
        "    # Calculate the correlation coefficients for all features\n",
        "    correlation_coefficients = calculate_correlation_coefficient(X_test, y_test)\n",
        "    lamda = 0.001\n",
        "    # Use SelectKBest to select the top 4 features based on correlation coefficient\n",
        "    select = SelectKBest(score_func=lambda X, y: correlation_coefficients, k=4)\n",
        "    X_selected = select.fit_transform(X_test, y_test)\n",
        "\n",
        "    mod_data[subj]['test']['mutual']['X'] = X_selected\n",
        "    mod_data[subj]['test']['mutual']['y'] = y_test\n",
        "    for j in range(X_selected.shape[0]):\n",
        "        row_data = [f'Subject_{subj}'] + X_selected[j, :].tolist() + [y_test[j]]\n",
        "        all_subjects_data.append(row_data)\n",
        "\n",
        "# Create DataFrame from collected data\n",
        "df = pd.DataFrame(all_subjects_data, columns=columns)\n",
        "\n",
        "# Save to Excel\n",
        "output_filename = 'selected_test_features_all_subjects.xlsx'\n",
        "df.to_excel(output_filename, index=False)"
      ],
      "metadata": {
        "id": "DJ9YhlWGDINQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantum SVM Classifier with Data from Excel for a Single Subject\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pennylane as qml\n",
        "from pennylane.templates.embeddings import AmplitudeEmbedding\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load data for a single subject from Excel files\n",
        "train_df = pd.read_excel('selected_train_features_all_subjects.xlsx')\n",
        "test_df = pd.read_excel('selected_test_features_all_subjects.xlsx')\n",
        "\n",
        "# Separate features and labels (assuming the last column is the label)\n",
        "X_train = train_df.iloc[:, 1:-1].values  # All columns except the first (subject) and last as features\n",
        "y_train = train_df.iloc[:, -1].values   # Last column as label\n",
        "X_test = test_df.iloc[:, 1:-1].values\n",
        "y_test = test_df.iloc[:, -1].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Quantum SVM setup\n",
        "n_qubits = X_train.shape[1]\n",
        "dev_kernel = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "projector = np.zeros((2 ** n_qubits, 2 ** n_qubits))\n",
        "projector[0, 0] = 1\n",
        "\n",
        "@qml.qnode(dev_kernel, interface=\"autograd\")\n",
        "def kernel(x1, x2):\n",
        "    \"\"\"Quantum kernel function.\"\"\"\n",
        "    AmplitudeEmbedding(x1, wires=range(n_qubits), pad_with=12.0)\n",
        "    qml.adjoint(AmplitudeEmbedding)(x2, wires=range(n_qubits), pad_with=12.0)\n",
        "    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))\n",
        "\n",
        "def kernel_matrix(A, B):\n",
        "    \"\"\"Compute kernel matrix for two datasets.\"\"\"\n",
        "    return np.array([[kernel(a, b) for b in B] for a in A])\n",
        "\n",
        "# Train Quantum SVM using custom kernel\n",
        "quantum_svm = SVC(kernel=lambda A, B: kernel_matrix(A, B)).fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier\n",
        "y_pred = quantum_svm.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "sensitivity_recall = recall_score(y_test, y_pred)\n",
        "specificity = recall_score(y_test, y_pred, pos_label=0)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Test Set Accuracy:\", test_accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Sensitivity (Recall):\", sensitivity_recall)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "4BQj7cLpDdSZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf-jupy",
      "language": "python",
      "name": "tf-jupy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}